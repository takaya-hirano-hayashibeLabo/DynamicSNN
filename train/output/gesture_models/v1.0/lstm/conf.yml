train:
  batch: 64
  epoch: 400
  iter: -1 #ここは-1にするとmaxまで. とりあえず20くらいでいい
  lr: 0.0005
  save_interval: 20 #epochごと
  datatype: gesture
  time-window: 3000 #μs (=3ms =0.003s)
  sequence: 300
  schedule-step: -1 #-1でscheduleなし
  schedule-rate: 0.5

model:
  type: lstm
  cnn-type: res #resで残差ブロックCNNになる

  in-size: 32
  in-channel: 2 
  out-size: 11
  hiddens: [12,32] 
  pool-type: avg
  pool-size: [2,2]
  residual-block: [3,3] #2にするとresidual blockあたり1+2層のCNNが積まれる
  is-bn: false #batch normalizationするかどうか. 
  dropout: 0.3

  linear-hidden: 512

  lstm-hidden-num: 2
  lstm-hidden: 256

  dt: 0.003 #s

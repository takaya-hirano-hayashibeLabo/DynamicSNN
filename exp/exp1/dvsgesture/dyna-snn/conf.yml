train:
  datapath: /mnt/ssd1/hiranotakaya/master/dev/workspace/prj_202409_2MR/laplace-version/train-data/xor_v2
  time_sequence: 100
  batch: 32
  epoch: 10
  iter: -1 #ここは-1にするとmaxまで
  lr: 0.001
  save_interval: 5 #epochごと
  datatype: dvsgesture

model:
  type: dynamic-snn
  cnn-type: res #resで残差ブロックCNNになる
  res-actfn: dyna-snn

  in-size: 32
  in-channel: 2 
  out-size: 11
  hiddens: [12,32] 
  pool-type: avg # avgにすることで,速度落としたときの1stepの情報量が落ちるようになる
  pool-size: [2,2]
  residual-block: [3,3] #2にするとresidual blockあたり1+2層のCNNが積まれる
  is-bn: false #batch normalizationするかどうか. 
  clip-norm: 1.0 #勾配クリッピングの最大勾配. 一般的に1.0が使われる

  linear-hidden: 32

  dropout: 0.2


  dt: 0.001 #s
  init-tau: 0.02 #dt/tauが1を超えないようにする.
  min-tau: 0.001
  v-threshold: 0.01
  v-rest: 0.0
  reset-mechanism: zero
  spike-grad: fast-sigmoid
  output-membrane: true
  # v-actf: tanh #膜電位vの活性化関数